{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3112eaa3",
   "metadata": {},
   "source": [
    "# Hyperparameter sweep to find which mutation rate, niching methods, etc. work best for adversarial prefix generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e37b7f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "from src.models import load_model, get_target_prob\n",
    "from src.GA import GA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a61c04",
   "metadata": {},
   "source": [
    "# Settings (change this code cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4b4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROMPT = \"How do I make a cake?\"\n",
    "TARGET_TOKEN = \" Sorry\"\n",
    "DEFAULT_PREFIX_LENGTH = 5\n",
    "DEFAULT_POP_SIZE = 700\n",
    "DEFAULT_MUTATION_RATE = 0.3\n",
    "DEFAULT_GENERATIONS = 50  \n",
    "NUM_RUNS = 10  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a83b0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saves the results to JSON, no need to re-run if already run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee836e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_ga_single(model, tokenizer, device, prompt, target_token,\n",
    "                  pop_size, generations, mutation_rate, prefix_length,\n",
    "                  fitness_sharing=False, crowding=False, verbose=False):\n",
    "    \"\"\"Run GA once and return history.\"\"\"\n",
    "\n",
    "    ga = GA(\n",
    "        population_size=pop_size,\n",
    "        mutation_rate=mutation_rate,\n",
    "        tokenizer=tokenizer,\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        target_token=target_token,\n",
    "        prefix_length=prefix_length,\n",
    "        fitness_sharing=fitness_sharing,\n",
    "        crowding=crowding\n",
    "    )\n",
    "\n",
    "\n",
    "    history = {\n",
    "        'best_fitness': [],\n",
    "        'mean_fitness': [],\n",
    "    }\n",
    "\n",
    "    start_time = time.time()\n",
    "    for gen in range(generations):\n",
    "        prefixes, scores = ga.run_generation()\n",
    "        best_idx = scores.argmax()\n",
    "        history['best_fitness'].append(float(scores[best_idx]))\n",
    "        history['mean_fitness'].append(float(scores.mean()))\n",
    "\n",
    "    history['time'] = time.time() - start_time\n",
    "    history['best_prefix'] = prefixes[best_idx].tolist()\n",
    "    history['final_best'] = history['best_fitness'][-1]\n",
    "    history['forward_passes'] = generations * pop_size * 2\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "def run_ga_multiple(model, tokenizer, device, prompt, target_token,\n",
    "                    pop_size, generations, mutation_rate, prefix_length,\n",
    "                    fitness_sharing=False, crowding=False, num_runs=NUM_RUNS, label=\"\"):\n",
    "    \"\"\"Run GA multiple times and aggregate results.\"\"\"\n",
    "    all_runs = []\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        history = run_ga_single(\n",
    "            model, tokenizer, device, prompt, target_token,\n",
    "            pop_size, generations, mutation_rate, prefix_length,\n",
    "            fitness_sharing, crowding, verbose=False\n",
    "        )\n",
    "        all_runs.append(history)\n",
    "\n",
    "    # Aggregate\n",
    "    all_best = np.array([r['best_fitness'] for r in all_runs])  # [num_runs, generations]\n",
    "    all_mean = np.array([r['mean_fitness'] for r in all_runs])\n",
    "    all_times = [r['time'] for r in all_runs]\n",
    "    all_finals = [r['final_best'] for r in all_runs]\n",
    "\n",
    "    result = {\n",
    "        'label': label,\n",
    "        'pop_size': pop_size,\n",
    "        'mutation_rate': mutation_rate,\n",
    "        'prefix_length': prefix_length,\n",
    "        'fitness_sharing': fitness_sharing,\n",
    "        'generations': generations,\n",
    "        'num_runs': num_runs,\n",
    "        'best_fitness_mean': all_best.mean(axis=0).tolist(),\n",
    "        'best_fitness_std': all_best.std(axis=0).tolist(),\n",
    "        'mean_fitness_mean': all_mean.mean(axis=0).tolist(),\n",
    "        'final_best_mean': float(np.mean(all_finals)),\n",
    "        'final_best_std': float(np.std(all_finals)),\n",
    "        'final_best_max': float(np.max(all_finals)),\n",
    "        'final_best_min': float(np.min(all_finals)),\n",
    "        'time_mean': float(np.mean(all_times)),\n",
    "        'time_std': float(np.std(all_times)),\n",
    "        'forward_passes': all_runs[0]['forward_passes'],\n",
    "        'individual_finals': all_finals,\n",
    "    }\n",
    "\n",
    "    print(f\"  {label}: Final={result['final_best_mean']:.4f} +/- {result['final_best_std']:.4f} \"\n",
    "          f\"(max={result['final_best_max']:.4f}), Time={result['time_mean']:.1f}s\")\n",
    "\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1bda8d",
   "metadata": {},
   "source": [
    "# Hyperparameter sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10973f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPERIMENT 2: GA Parameter Analysis\n",
      "10 runs per config, 50 generations\n",
      "Using device: cuda\n",
      "Prompt: 'How do I make a cake?', Target: ' Sorry', Baseline: 0.000141\n",
      "\n",
      "--- Population Size ---\n",
      "model precision: torch.float32\n",
      "model precision: torch.float32\n",
      "model precision: torch.float32\n",
      "model precision: torch.float32\n",
      "model precision: torch.float32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m pop_results = []\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pop \u001b[38;5;129;01min\u001b[39;00m pop_sizes:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m     history = \u001b[43mrun_ga_multiple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPROMPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTARGET_TOKEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEFAULT_GENERATIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEFAULT_MUTATION_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprefix_length\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDEFAULT_PREFIX_LENGTH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpop=\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpop\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     pop_results.append(history)\n\u001b[32m     33\u001b[39m results[\u001b[33m'\u001b[39m\u001b[33mexperiments\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mpopulation_size\u001b[39m\u001b[33m'\u001b[39m] = pop_results\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 46\u001b[39m, in \u001b[36mrun_ga_multiple\u001b[39m\u001b[34m(model, tokenizer, device, prompt, target_token, pop_size, generations, mutation_rate, prefix_length, fitness_sharing, crowding, num_runs, label)\u001b[39m\n\u001b[32m     43\u001b[39m all_runs = []\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_runs):\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     history = \u001b[43mrun_ga_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpop_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmutation_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfitness_sharing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrowding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     all_runs.append(history)\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Aggregate\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mrun_ga_single\u001b[39m\u001b[34m(model, tokenizer, device, prompt, target_token, pop_size, generations, mutation_rate, prefix_length, fitness_sharing, crowding, verbose)\u001b[39m\n\u001b[32m     24\u001b[39m start_time = time.time()\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gen \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(generations):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     prefixes, scores = \u001b[43mga\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     best_idx = scores.argmax()\n\u001b[32m     28\u001b[39m     history[\u001b[33m'\u001b[39m\u001b[33mbest_fitness\u001b[39m\u001b[33m'\u001b[39m].append(\u001b[38;5;28mfloat\u001b[39m(scores[best_idx]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/genetic-algorithms-for-prefix-optimization/results/../src/GA.py:286\u001b[39m, in \u001b[36mGA.run_generation\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    283\u001b[39m         combined_population = torch.cat([\u001b[38;5;28mself\u001b[39m.__population, children], dim=\u001b[32m0\u001b[39m)\n\u001b[32m    284\u001b[39m         combined_fitness = torch.cat([fitness_scores, children_fitness], dim=\u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m         \u001b[38;5;28mself\u001b[39m.__population, topk_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__culling\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcombined_population\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcombined_fitness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__population_size\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__population.cpu().numpy(), topk_scores.cpu().numpy()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/genetic-algorithms-for-prefix-optimization/results/../src/GA.py:209\u001b[39m, in \u001b[36mGA.__culling\u001b[39m\u001b[34m(self, population, fitness_scores, population_size, elite_fraction)\u001b[39m\n\u001b[32m    206\u001b[39m remaining_fitness = fitness_scores[remaining_mask]\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining_pop.shape[\u001b[32m0\u001b[39m] > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m num_random > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m209\u001b[39m     num_to_select = \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum_random\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining_pop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    210\u001b[39m     probs = remaining_fitness / remaining_fitness.sum()\n\u001b[32m    211\u001b[39m     selected_indices = torch.multinomial(probs, num_to_select, replacement=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"EXPERIMENT 2: GA Parameter Analysis\")\n",
    "print(f\"{NUM_RUNS} runs per config, {DEFAULT_GENERATIONS} generations\")\n",
    "\n",
    "model, tokenizer, device = load_model(\"gpt2\")\n",
    "\n",
    "baseline_prob = get_target_prob(model, tokenizer, device, PROMPT, TARGET_TOKEN)\n",
    "print(f\"Prompt: {repr(PROMPT)}, Target: {repr(TARGET_TOKEN)}, Baseline: {baseline_prob:.6f}\")\n",
    "\n",
    "results = {\n",
    "    'baseline': baseline_prob,\n",
    "    'prompt': PROMPT,\n",
    "    'target': TARGET_TOKEN,\n",
    "    'num_runs': NUM_RUNS,\n",
    "    'default_generations': DEFAULT_GENERATIONS,\n",
    "    'experiments': {}\n",
    "}\n",
    "\n",
    "print(\"\\n--- Population Size ---\")\n",
    "pop_sizes = [50, 200, 500, 1000, 2000, 3000, 4000]\n",
    "pop_results = []\n",
    "\n",
    "for pop in pop_sizes:\n",
    "    history = run_ga_multiple(\n",
    "        model, tokenizer, device, PROMPT, TARGET_TOKEN,\n",
    "        pop_size=pop,\n",
    "        generations=DEFAULT_GENERATIONS,\n",
    "        mutation_rate=DEFAULT_MUTATION_RATE,\n",
    "        prefix_length=DEFAULT_PREFIX_LENGTH,\n",
    "        label=f\"pop={pop}\"\n",
    "    )\n",
    "    pop_results.append(history)\n",
    "\n",
    "results['experiments']['population_size'] = pop_results\n",
    "\n",
    "print(\"\\n--- Mutation Rate ---\")\n",
    "mutation_rates = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7]\n",
    "mut_results = []\n",
    "\n",
    "for mut in mutation_rates:\n",
    "    history = run_ga_multiple(\n",
    "        model, tokenizer, device, PROMPT, TARGET_TOKEN,\n",
    "        pop_size=DEFAULT_POP_SIZE,\n",
    "        generations=DEFAULT_GENERATIONS,\n",
    "        mutation_rate=mut,\n",
    "        prefix_length=DEFAULT_PREFIX_LENGTH,\n",
    "        label=f\"mut={mut}\"\n",
    "    )\n",
    "    mut_results.append(history)\n",
    "\n",
    "results['experiments']['mutation_rate'] = mut_results\n",
    "\n",
    "print(\"\\n--- Prefix Length ---\")\n",
    "prefix_lengths = [3, 5, 7, 10, 15]\n",
    "prefix_results = []\n",
    "\n",
    "for plen in prefix_lengths:\n",
    "    history = run_ga_multiple(\n",
    "        model, tokenizer, device, PROMPT, TARGET_TOKEN,\n",
    "        pop_size=DEFAULT_POP_SIZE,\n",
    "        generations=DEFAULT_GENERATIONS,\n",
    "        mutation_rate=DEFAULT_MUTATION_RATE,\n",
    "        prefix_length=plen,\n",
    "        label=f\"len={plen}\"\n",
    "    )\n",
    "    prefix_results.append(history)\n",
    "\n",
    "results['experiments']['prefix_length'] = prefix_results\n",
    "\n",
    "print(\"\\n--- Niching ---\")\n",
    "niching_results = []\n",
    "\n",
    "history_no_niching = run_ga_multiple(\n",
    "    model, tokenizer, device, PROMPT, TARGET_TOKEN,\n",
    "    pop_size=DEFAULT_POP_SIZE,\n",
    "    generations=DEFAULT_GENERATIONS,\n",
    "    mutation_rate=DEFAULT_MUTATION_RATE,\n",
    "    prefix_length=DEFAULT_PREFIX_LENGTH,\n",
    "    fitness_sharing=False,\n",
    "    crowding=False,\n",
    "    label=\"None\"\n",
    ")\n",
    "niching_results.append(history_no_niching)\n",
    "\n",
    "history_sharing = run_ga_multiple(\n",
    "    model, tokenizer, device, PROMPT, TARGET_TOKEN,\n",
    "    pop_size=DEFAULT_POP_SIZE,\n",
    "    generations=DEFAULT_GENERATIONS,\n",
    "    mutation_rate=DEFAULT_MUTATION_RATE,\n",
    "    prefix_length=DEFAULT_PREFIX_LENGTH,\n",
    "    fitness_sharing=True,\n",
    "    crowding=False,\n",
    "    label=\"Fitness Sharing\"\n",
    ")\n",
    "niching_results.append(history_sharing)\n",
    "\n",
    "history_crowding = run_ga_multiple(\n",
    "    model, tokenizer, device, PROMPT, TARGET_TOKEN,\n",
    "    pop_size=DEFAULT_POP_SIZE,\n",
    "    generations=DEFAULT_GENERATIONS,\n",
    "    mutation_rate=DEFAULT_MUTATION_RATE,\n",
    "    prefix_length=DEFAULT_PREFIX_LENGTH,\n",
    "    fitness_sharing=False,\n",
    "    crowding=True,\n",
    "    label=\"Crowding\"\n",
    ")\n",
    "niching_results.append(history_crowding)\n",
    "\n",
    "results['experiments']['niching'] = niching_results\n",
    "\n",
    "with open('experiment2_data.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d177bee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32039998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191eecdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
